<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
    <!-- configuration hadoop -->
        <property>
    <!-- 
        HDFS의 논리적 네임서비스 식별자를 지정
        고가용성 구성 및 Federation 구성에서 사용
     -->
        <name>dfs.nameservices</name>
        <value>geon-hadoop-cluster</value>
    </property>
    <property>
    <!-- 
        지정된 논리적 네임서비스에 대한
        고가용성 네임노드 식별자를 지정
     -->
        <name>dfs.ha.namenodes.geon-hadoop-cluster</name>
        <value>namenode1,namenode2</value>
    </property>
    <property>
    <!-- 
        고가용성 구성에서 네임노드가JournalNode에 대한
        편집 로그를 공유할 수 있도록 구성된 URI를 지정
     -->
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://nn1:8485;nn2:8485;dn1:8485/geon-hadoop-cluster</value>
    </property>
    <property>
    <!-- HDFS의 데이터 복제 계수 -->
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
    <!-- 
        HDFS의 기본 블록 크기
        블록 크기를 늘리면 대용량 파일의 처리가 개선된다.
        너무 작은 블록 크기는 NameNode의 메모리 사용량을 늘릴 수 있다.
     -->
        <name>dfs.blocksize</name>
        <value>134217728</value> <!-- 예시: 128MB -->
    </property>
    <property>
    <!-- 
        NameNode의 메타데이터가 저장되는 디렉토리를 지정, 이 디렉토리는 NameNode가 시작될 때 사용
        파일 시스템 이미지 및 에디트 로그가 저장된다.
    -->
        <name>dfs.namenode.name.dir</name>
        <value>/usr/local/hadoop/data/nameNode</value>
    </property>
    <property>
    <!-- DataNode에서 사용되는 HDFS 데이터 디렉토리를 지정한다. 여기에 데이터 블록이 저장된다. -->
        <name>dfs.datanode.data.dir</name>
        <value>/usr/local/hadoop/data/dataNode</value>
    </property>
    </property>
    <property>
    <!-- NameNode에 대한 RPC(Remote Procedure Call) 주소 -->
        <name>dfs.namenode.rpc-address.geon-hadoop-cluster.namenode1</name>
        <value>nn1:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.geon-hadoop-cluster.namenode2</name>
        <value>nn2:8020</value>
    </property>
    <property>
    <!--
        NameNode의 HTTP 및 HTTPS 웹 인터페이스가 사용하는 IP 주소와 포트 번호를 지정 
        이 설정을 사용하면 웹 인터페이스에 대한 액세스를 제어
     -->
        <name>dfs.namenode.http-address.geon-hadoop-cluster.namenode1</name>
        <value>nn1:50070</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.geon-hadoop-cluster.namenode2</name>
        <value>nn2:50070</value>
    </property>
    <property>
    <!-- 
         Secondary NameNode의 HTTP 주소를 지정 
         클러스터 관리자와 다른 서비스가 Secondary NameNode와 통신
     -->
        <name>dfs.namenode.secondary.http-address</name>
         <value>nn2:50080</value>
    </property>
    <property>
    <!-- 
        데이터노드 웹UI 데이터 노드의 상태, 로그등을 확인할 수 있음
     -->
        <name>dfs.datanode.http.address</name>
        <value>dn1:9120</value>
    </property>
    <property>
    <!-- 
        WebHDFS REST API
        기본값은 true 
        원격 클라이언트와 애플리케이션에서 HDFS를 사용 가능
     -->
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>
    <property>
    <!-- 
        HDFS 클라이언트가 DataNode와 통신할 때 IP 주소 대신 호스트 이름을 사용할지 지정 
        네트워크 구성에 따라 이 설정값을 변경할 수 있다. 
        기본값은 false
     -->
        <name>dfs.client.use.datanode.hostname</name>
        <value>false</value>
    </property>
    <property>
    <!-- 
        클라이언트가 HDFS 블록 파일을 
        직접 여는 단락 로컬 읽기의 레거시 구현은 
        Linux 이외의 플랫폼에서 계속 사용할 수 있습니다
     -->
        <name>dfs.client.read.shortcircuit</name>
        <value>true</value>
    </property>
    <property>
    <!-- 
        HDFS 클라이언트가 짧은 회로 읽기를 수행할 때 
        체크섬 검사를 건너뛸지 여부를 지정합니다. 
        기본값은 false로 설정되어 있어 체크섬 검사를 수행하도록 되어 있습니다.
        이 값을 true로 설정하면 성능은 향상되지만, 
        데이터 무결성에 문제가 발생할 수 있습니다.
     -->
        <name>dfs.client.read.shortcircuit.skip.checksum</name>
        <value>true</value>
    </property>
    <property>
    <!-- 
        DataNode 실패 시 블록 쓰기를 다른 DataNode로 전환하는 정책을 지정
        기본값은 "NEVER"로 설정되어 있으며, 실패한 DataNode를 대체하지 안한다.
     -->
        <name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
        <value>NEVER</value>
    </property>
    <property>
    <!-- 
        클라이언트가 파일을 읽을 때 미리 읽을 바이트 수를 지정
        기본값은 4MB 
        클라이언트 캐시 성능이 향상되지만, 메모리 사용량이 증가
     -->
        <name>dfs.client.cache.readahead</name>
        <value>4194304</value>
    </property>
    <property>
    <!-- 
         NameNode에서 한 번의 반복에서 처리하는 복제 작업의 수를 지정
         기본값은 2 
         값을 높이면 NameNode가 더 많은 복제 작업을 빠르게 처리
         높은 복제 작업 부하로 인해 NameNode의 성능에 영향
     -->
        <name>dfs.namenode.replication.work.multiplier.per.iteration</name>
        <value>2</value>
    </property>
    <property>
    <!-- 
        각 DataNode에서 실행되는 핸들러 스레드의 수를 지정
        기본값은 10 
        값을 높이면 동시에 처리할 수 있는 클라이언트 요청이 증가하지만, 
        CPU와 메모리 사용량이 더 많아진다.
     -->
        <name>dfs.datanode.handler.count</name>
        <value>10</value>
    </property>
    <property>
    <!-- NameNode가 DataNode의 분산 및 복제 상태를 확인하는 간격(초 단위) -->
        <name>dfs.namenode.decommission.interval</name>
        <value>30</value>
    </property>
    <property>
    <!-- 
         Secondary NameNode가 체크포인트를 생성하는 주기를 지정
         기본값은 3600초(1시간)
     -->
        <name>dfs.namenode.checkpoint.period</name>
        <value>3600</value>
    </property>
    <property>
    <!-- 
        Secondary NameNode 또는 CheckpointNode가 
        NameNode의 메타데이터를 가져와서 체크포인트를 생성하는 주기를 초 단위로 지정 
    -->
        <name>dfs.namenode.checkpoint.period</name>
        <value>3600</value>
    </property>
    <property>
    <!-- 체크포인트를 생성하기 전에 처리되어야 하는 트랜잭션의 수 -->
        <name>dfs.namenode.checkpoint.txns</name>
        <value>1000000</value>
    </property>
    <property>
    <!-- 
        DataNode 간의 밸런싱 작업에서 사용할 수 있는 최대 대역폭(바이트 단위)을 지정
        기본값은 1,048,576 바이트(1MB)
        값을 늘리면 더 빠른 밸런싱 작업이 가능하지만, 
        네트워크 대역폭 많이 사용
     -->
        <name>dfs.datanode.balance.bandwidthPerSec</name>
        <value>1048576</value>
    </property>
    <property>
    <!-- 
        DataNode 간 데이터 전송을 암호화할지 여부를 지정
     -->
        <name>dfs.encrypt.data.transfer</name>
        <value>false</value>
    </property>
    <property>
    <!-- 
        DataNode에서 사용하는 데이터 디렉터리의 권한을 지정
        기본값은 700
        HDFS 데이터 디렉터리의 보안을 강화할 수 있다.
     -->
        <name>dfs.datanode.data.dir.perm</name>
        <value>777</value>
    </property>
    <property>
    <!-- NameNode가 안전 모드에서 시작할 때 필요한 최소 블록 복제 비율 --> 
        <name>dfs.namenode.safemode.threshold-pct</name>
        <value>0.999f</value>
    </property>
    <property>
    <!-- 
        HDFS 클러스터의 노드 간 데이터 균형 조정 작업에 사용되는 대역폭을 지정
        기본값은 1MB/s
        이 값을 높이면 노드 간 데이터 균형 조정 작업이 더 빠르게 수행되지만, 다른 작업에 미치는 영향이 커질 수 있다.
     -->
        <name>dfs.datanode.balance.bandwidthPerSec</name>
        <value>1048576</value>
    </property>
    <property>
    <!-- 클라이언트가 읽기 작업을 수행할 때 오래된 DataNode를 피할지 여부를 지정 -->
        <name>dfs.namenode.avoid.read.stale.datanode</name>
        <value>true</value>
    </property>
    <property>
    <!-- HDFS에 대한 사용자 및 그룹 권한 검사를 활성화 하거나 비활성화 한다. -->
        <name>dfs.permissions.enabled</name>
        <value>false</value>
    </property>
    <property>
    <!-- 
         HDFS의 고가용성(HA) 구성에서 사용되며
         JournalNode에서 편집 로그를 저장하는 경로를 지정
     -->
        <name>dfs.journalnode.edits.dir</name>
        <value>/usr/local/hadoop/data/dfs/journalnode</value>
    </property>
    <property>
    <!-- 
        고가용성 클러스터에서 자동 장애 조치 프록시 공급자를 지정
        클라이언트가 고가용성 네임노드 중 어떤 것과 통신할지 결정하는데 사용
     -->
        <name>dfs.client.failover.proxy.provider.geon-hadoop-cluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
    <!-- 
        네임노드 간의 장애 조치(failover)를 처리하기 위한 펜싱 방법을 지정
        sshfence는 SSH를 사용하여 다른 네임노드를 격리하는 방법
     -->
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
    </property>
    <property>
    <!-- 
        SSH 펜싱을 사용할 때 사용되는 개인 키 파일의 경로를 지정
     -->
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/geon/.ssh/id_rsa</value>
    </property>
    <property> 
    <!-- 
        자동 장애 조치 기능 
        true로 설정되면 하나의 네임노드가 실패할 경우 자동으로 다른 네임노드로 전환
     -->
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    <property>
    <!-- 네임노드의 메타데이터를 저장할 디렉터리를 지정 -->
        <name>dfs.name.dir</name>
        <value>/usr/local/hadoop/data/name</value>
    </property>
    <property>
    <!-- 데이터노드의 HDFS 데이터를 저장할 디렉터리를 지정 -->
        <name>dfs.data.dir</name>
        <value>/usr/local/hadoop/data/data</value>
    </property>
</configuration>